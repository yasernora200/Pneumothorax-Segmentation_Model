from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import torch
import numpy as np
import cv2
import base64
from datetime import datetime
from PIL import Image
import io
from model_arch import SwinUNet  # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„

app = FastAPI(title="Pneumothorax Segmentation API")

# Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ù† Ø£ÙŠ Ù…ÙƒØ§Ù† (Ø¹Ø´Ø§Ù† Ù„Ùˆ Ù‡ØªØ±Ø¨Ø·Ù‡ Ø¨Ù€ Frontend)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables
model = None
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@app.on_event("startup")
async def load_model():
    global model
    try:
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
        model = SwinUNet(num_classes=1, pretrained=False)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† (ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ØµØ­)
        checkpoint = torch.load("best_swin_unet.pth", map_location=device)
        
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø³ÙˆØ§Ø¡ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù checkpoint ÙƒØ§Ù…Ù„ Ø£Ùˆ state_dict Ø¨Ø³
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
            
        model.to(device)
        model.eval()
        print(f"âœ… Model loaded successfully on {device}")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")

def mask_to_base64(mask_np):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø§Ø³Ùƒ (Numpy Array) Ù„ØµÙˆØ±Ø© Base64 Ø´ÙØ§ÙØ© (RGBA) Ù„ØªØ¸Ù‡Ø± Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø­Ù…Ø±"""
    h, w = mask_np.shape
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø¨Ø±Ø¨Ø¹ Ù‚Ù†ÙˆØ§Øª (BGRA) - Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ„Ù‡Ø§ Ø£ØµÙØ§Ø± (Ø´ÙØ§ÙØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„)
    img_bgra = np.zeros((h, w, 4), dtype=np.uint8)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ù…Ø§Ø³Ùƒ (Ø§Ù„Ù‚ÙŠÙ…Ø© 1)
    # Ø§Ù„Ù‚Ù†Ø§Ø© 2 (Ø§Ù„Ø£Ø­Ù…Ø±) = 255
    img_bgra[mask_np == 1, 2] = 255 
    # Ø§Ù„Ù‚Ù†Ø§Ø© 3 (Ø§Ù„Ø´ÙØ§ÙÙŠØ© Alpha) = 127 (Ù†ØµÙ Ø´ÙØ§ÙØ©)
    img_bgra[mask_np == 1, 3] = 127
    
    _, buffer = cv2.imencode('.png', img_bgra)
    return "data:image/png;base64," + base64.b64encode(buffer).decode("utf-8")

@app.post("/predict")
async def predict_pneumothorax(file: UploadFile = File(...)):
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    start_time = datetime.now()

    # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
    contents = await file.read()
    image_pil = Image.open(io.BytesIO(contents)).convert("L") # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Grayscale
    original_size = image_pil.size # (W, H)
    
    # 2. Preprocessing (Ø²ÙŠ Ø§Ù„Ù€ Notebook Cell 75)
    image_np = np.array(image_pil)
    image_resized = cv2.resize(image_np, (224, 224))
    image_tensor = torch.from_numpy(image_resized).float() / 255.0
    image_tensor = image_tensor.unsqueeze(0).unsqueeze(0).to(device) # (1, 1, 224, 224)

    # 3. Prediction
    with torch.no_grad():
        output = model(image_tensor)
        prob_map = torch.sigmoid(output)
        max_prob = prob_map.max().item()
        
        # --- Dynamic Thresholding ---
        # Ù„Ùˆ Ø§Ù„Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ø³ØªØ®Ø¯Ù… 0.5
        # Ù„Ùˆ Ø§Ù„Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© (0.25 - 0.5) Ù†Ø²Ù„ Ø§Ù„Ù€ Threshold Ø­Ø³Ø¨ Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø©
        # Ù„Ùˆ Ø£Ù‚Ù„ Ù…Ù† ÙƒØ¯Ø§ Ø§Ø¹ØªØ¨Ø±Ù‡Ø§ ØµÙˆØ±Ø© Ø³Ù„ÙŠÙ…Ø©
        threshold = 0.5
        if max_prob < 0.5:
            if max_prob > 0.25:
                threshold = max_prob * 0.9 # Ø®Ø¯ Ø§Ø¹Ù„Ù‰ 10% Ù…Ù† Ø§Ù„Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø´Ø§ÙƒÙƒ ÙÙŠÙ‡
                print(f"âš ï¸ Low confidence ({max_prob:.4f}). Dynamic threshold: {threshold:.4f}")
            else:
                threshold = 1.0 # Ù…Ø³ØªØ­ÙŠÙ„ ÙŠØªØ­Ù‚Ù‚ -> Ù…Ø§Ø³Ùƒ ÙØ§Ø¶ÙŠ
                print(f"âœ… No confident detection ({max_prob:.4f}).")
        else:
             print(f"ğŸš€ High confidence ({max_prob:.4f}). Standard threshold.")
        # ----------------------------

        pred_mask = (prob_map > threshold).float()

    # 4. Post-processing & Analysis
    pred_mask_np = pred_mask.squeeze().cpu().numpy().astype(np.uint8)
    
    # --- Morphological Cleanup to remove noise ---
    kernel = np.ones((5,5), np.uint8)
    pred_mask_np = cv2.morphologyEx(pred_mask_np, cv2.MORPH_OPEN, kernel) # Remove small noise
    pred_mask_np = cv2.morphologyEx(pred_mask_np, cv2.MORPH_CLOSE, kernel) # Close gaps
    # ---------------------------------------------
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ØµØ§Ø¨Ø©
    affected_pixels = np.count_nonzero(pred_mask_np)
    total_pixels = pred_mask_np.size
    affected_area_pct = (affected_pixels / total_pixels) * 100
    
    # --- SANITY CHECK: Suppress Large Noise ---
    if affected_area_pct > 40.0:
        print(f"âš ï¸ Mask covers {affected_area_pct:.1f}% of image. Suspected noise. Suppressing.")
        pred_mask_np[:] = 0
        affected_area_pct = 0.0
    # ------------------------------------------
    
    # ØªØ­Ø¯ÙŠØ¯ Ø´Ø¯Ø© Ø§Ù„Ø¥ØµØ§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø³Ø¨Ø©
    severity = "None"
    if affected_area_pct > 0:
        if affected_area_pct < 10: severity = "Mild"
        elif affected_area_pct < 30: severity = "Moderate"
        else: severity = "Severe"

    # Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ù…Ø§Ø³Ùƒ Ù„Ù„Ø­Ø¬Ù… Ø§Ù„Ø£ØµÙ„ÙŠ Ø¹Ø´Ø§Ù† ÙŠØ±Ø¬Ø¹ ÙÙŠ Ø§Ù„Ù€ JSON
    final_mask = cv2.resize(pred_mask_np, original_size, interpolation=cv2.INTER_NEAREST)
    
    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·Ø¨ÙŠØ©
    findings = []
    if affected_area_pct > 0:
        findings.append("Pneumothorax identified.")
        findings.append(f"Approximately {affected_area_pct:.1f}% lung field involved.")
        findings.append("Immediate clinical correlation recommended.")
    else:
        findings.append("No Pneumothorax detected.")
        findings.append("Lung fields appear clear.")

    # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°
    execution_time = (datetime.now() - start_time).total_seconds()

    # 5. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ JSON response Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    response = {
        "hasPneumothorax": bool(affected_area_pct > 0),
        "confidence": float(prob_map.max().item() * 100) if affected_area_pct > 0 else float((1 - prob_map.max().item()) * 100),
        "affectedArea": round(affected_area_pct, 1),
        "severity": severity,
        "location": "Detected Region", # ÙŠØ­ØªØ§Ø¬ Ù…ÙˆØ¯ÙŠÙ„ Detection Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ§Ù† Ø¨Ø¯Ù‚Ø© (Upper/Lower)
        "segmentationMap": mask_to_base64(final_mask),
        "maskOverlay": mask_to_base64(final_mask), # ÙÙŠ Ø§Ù„ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯ Ù‡ÙŠØ­Ø·Ù‡Ø§ ÙÙˆÙ‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        "detectionTime": f"{execution_time:.3f}s",
        "timestamp": datetime.now().isoformat(),
        "patientId": "Unknown", # Ø¨ÙŠÙŠØ¬ÙŠ Ø¹Ø§Ø¯Ø© Ù…Ù† Ø§Ù„Ù€ Request Header Ø£Ùˆ Ø§Ù„Ù€ Frontend
        "metrics": {
            "precision": 0.0, # Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨Ù‡ Ø¨Ø¯Ù‚Ø© Ø¨Ø¯ÙˆÙ† Ground Truth Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            "recall": 0.0,
            "iou": 0.0,
            "diceScore": 0.0
        },
        "findings": findings
    }
    
    return response